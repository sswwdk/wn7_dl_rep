{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "61ae5595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch 2.6.0+cu124 cuda 12.4 is_available True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"torch\", torch.__version__,\n",
    "      \"cuda\", torch.version.cuda,\n",
    "      \"is_available\",\n",
    "      torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2672afb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ZkX3dtMqzOMNLiZ359qg'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "loaded = load_dotenv()\n",
    "os.getenv('ROBOFLOW_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9ff1b29e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<inference_sdk.http.client.InferenceHTTPClient at 0x2a0a671c370>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from inference_sdk import InferenceHTTPClient\n",
    "CLIENT = InferenceHTTPClient(\n",
    "api_url=\"https://detect.roboflow.com\",\n",
    "api_key=os.getenv('ROBOFLOW_API_KEY')\n",
    ")\n",
    "CLIENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c4627c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'inference_id': '4dd9e13f-476a-4734-a6ac-9302ba29096d', 'time': 0.036257932999888, 'image': {'width': 512, 'height': 341}, 'predictions': [{'x': 404.0, 'y': 233.5, 'width': 132.0, 'height': 151.0, 'confidence': 0.9074662923812866, 'class': 'Rock', 'class_id': 1, 'detection_id': 'bfd105d4-3c27-48ca-b42a-87c659c5a5b7'}, {'x': 112.5, 'y': 223.0, 'width': 175.0, 'height': 210.0, 'confidence': 0.8111773729324341, 'class': 'Paper', 'class_id': 0, 'detection_id': 'aebd0530-bbda-4823-acae-067a8050ec36'}]}\n"
     ]
    }
   ],
   "source": [
    "result = CLIENT.infer('sample.jpg', model_id=\"rock-paper-scissors-sxsw/14\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9d33cb94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'inference_id': '37e36f30-bb6c-40d1-a574-1379df8e6b93',\n",
       " 'time': 0.03528598000002603,\n",
       " 'image': {'width': 512, 'height': 341},\n",
       " 'predictions': [{'x': 404.0,\n",
       "   'y': 233.5,\n",
       "   'width': 132.0,\n",
       "   'height': 151.0,\n",
       "   'confidence': 0.9074662923812866,\n",
       "   'class': 'Rock',\n",
       "   'class_id': 1,\n",
       "   'detection_id': '7c5243f2-e3cb-4ef8-8fa4-df153d5479f4'},\n",
       "  {'x': 112.5,\n",
       "   'y': 223.0,\n",
       "   'width': 175.0,\n",
       "   'height': 210.0,\n",
       "   'confidence': 0.8111773729324341,\n",
       "   'class': 'Paper',\n",
       "   'class_id': 0,\n",
       "   'detection_id': '6cf65875-7214-40da-85bc-a6619b1804e6'}]}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = CLIENT.infer('sample.jpg', model_id='rock-paper-scissors-sxsw/14')\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dec0eaae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404.0 233.5 132.0 151.0 0.9074662923812866 Rock\n",
      "112.5 223.0 175.0 210.0 0.8111773729324341 Paper\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "img = cv2.imread('sample.jpg')\n",
    "\n",
    "for pred in result['predictions']:\n",
    "    x = pred['x']\n",
    "    y = pred['y']\n",
    "    width = pred['width']\n",
    "    height = pred['height']\n",
    "    conf = pred['confidence']\n",
    "    obj_class = pred['class']\n",
    "    \n",
    "    x1, y1 = int(x-width/2), int(y-height/2)\n",
    "    x2, y2 = int(x+width/2), int(y+height/2)\n",
    "    cv2.rectangle(img, (x1,y1), (x2, y2), (0,0,255), 2)\n",
    "    cv2.putText(img, f'{obj_class} {conf:.4f}', (x1,y1), cv2.FONT_HERSHEY_PLAIN, 2, (0,0,255))\n",
    "    \n",
    "    print(x,y,width,height,conf,obj_class)\n",
    "\n",
    "cv2.imshow('image', img)\n",
    "cv2.waitKey() # 별도의 창이 열림, 닫지 않게끔 설정\n",
    "cv2.destroyAllWindows() # 창 닫으면 종료."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1fcf55dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[150, 159, 202],\n",
       "        [152, 161, 204],\n",
       "        [151, 160, 203],\n",
       "        ...,\n",
       "        [138, 155, 198],\n",
       "        [139, 156, 199],\n",
       "        [139, 156, 199]],\n",
       "\n",
       "       [[150, 159, 202],\n",
       "        [152, 161, 204],\n",
       "        [151, 160, 203],\n",
       "        ...,\n",
       "        [138, 155, 198],\n",
       "        [138, 155, 198],\n",
       "        [138, 155, 198]],\n",
       "\n",
       "       [[150, 159, 202],\n",
       "        [152, 161, 204],\n",
       "        [151, 160, 203],\n",
       "        ...,\n",
       "        [137, 154, 197],\n",
       "        [138, 155, 198],\n",
       "        [138, 155, 198]]], dtype=uint8)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "filename = 'sample.jpg'\n",
    "cv2.imread(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d1720169",
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPCallErrorError",
     "evalue": "HTTPCallErrorError(description='400 Client Error: Bad Request for url: https://detect.roboflow.com/digital-numbers-v3ajx/1?api_key=Zk***qg&disable_active_learning=False', api_message='Could not load input image. Cause: Malformed base64 input image.',status_code=400)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\envs\\torch_cuda_yolo_env\\lib\\site-packages\\inference_sdk\\http\\client.py:94\u001b[0m, in \u001b[0;36mwrap_errors.<locals>.decorate\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 94\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m function(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m error:\n",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\envs\\torch_cuda_yolo_env\\lib\\site-packages\\inference_sdk\\http\\client.py:400\u001b[0m, in \u001b[0;36mInferenceHTTPClient.infer\u001b[1;34m(self, inference_input, model_id)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__client_mode \u001b[38;5;129;01mis\u001b[39;00m HTTPClientMode\u001b[38;5;241m.\u001b[39mV0:\n\u001b[1;32m--> 400\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer_from_api_v0\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    401\u001b[0m \u001b[43m        \u001b[49m\u001b[43minference_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minference_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    402\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    403\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    404\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfer_from_api_v1(\n\u001b[0;32m    405\u001b[0m     inference_input\u001b[38;5;241m=\u001b[39minference_input,\n\u001b[0;32m    406\u001b[0m     model_id\u001b[38;5;241m=\u001b[39mmodel_id,\n\u001b[0;32m    407\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\envs\\torch_cuda_yolo_env\\lib\\site-packages\\inference_sdk\\http\\client.py:489\u001b[0m, in \u001b[0;36mInferenceHTTPClient.infer_from_api_v0\u001b[1;34m(self, inference_input, model_id)\u001b[0m\n\u001b[0;32m    480\u001b[0m requests_data \u001b[38;5;241m=\u001b[39m prepare_requests_data(\n\u001b[0;32m    481\u001b[0m     url\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__api_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_id_chunks[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_id_chunks[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    482\u001b[0m     encoded_inference_inputs\u001b[38;5;241m=\u001b[39mencoded_inference_inputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    487\u001b[0m     image_placement\u001b[38;5;241m=\u001b[39mImagePlacement\u001b[38;5;241m.\u001b[39mDATA,\n\u001b[0;32m    488\u001b[0m )\n\u001b[1;32m--> 489\u001b[0m responses \u001b[38;5;241m=\u001b[39m \u001b[43mexecute_requests_packages\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequests_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequests_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mRequestMethod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPOST\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_concurrent_requests\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__inference_configuration\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_concurrent_requests\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    494\u001b[0m results \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\envs\\torch_cuda_yolo_env\\lib\\site-packages\\inference_sdk\\http\\utils\\executors.py:65\u001b[0m, in \u001b[0;36mexecute_requests_packages\u001b[1;34m(requests_data, request_method, max_concurrent_requests)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m response \u001b[38;5;129;01min\u001b[39;00m results:\n\u001b[1;32m---> 65\u001b[0m     \u001b[43mapi_key_safe_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\envs\\torch_cuda_yolo_env\\lib\\site-packages\\inference_sdk\\http\\utils\\requests.py:21\u001b[0m, in \u001b[0;36mapi_key_safe_raise_for_status\u001b[1;34m(response)\u001b[0m\n\u001b[0;32m     20\u001b[0m response\u001b[38;5;241m.\u001b[39murl \u001b[38;5;241m=\u001b[39m deduct_api_key_from_string(value\u001b[38;5;241m=\u001b[39mresponse\u001b[38;5;241m.\u001b[39murl)\n\u001b[1;32m---> 21\u001b[0m \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\envs\\torch_cuda_yolo_env\\lib\\site-packages\\requests\\models.py:1026\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1025\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[1;32m-> 1026\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[1;31mHTTPError\u001b[0m: 400 Client Error: Bad Request for url: https://detect.roboflow.com/digital-numbers-v3ajx/1?api_key=Zk***qg&disable_active_learning=False",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mHTTPCallErrorError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mCLIENT\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmnist_train/000001.jpg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdigital-numbers-v3ajx/1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(result)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\envs\\torch_cuda_yolo_env\\lib\\site-packages\\inference_sdk\\http\\client.py:104\u001b[0m, in \u001b[0;36mwrap_errors.<locals>.decorate\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    103\u001b[0m         api_message \u001b[38;5;241m=\u001b[39m error\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mtext\n\u001b[1;32m--> 104\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPCallErrorError(\n\u001b[0;32m    105\u001b[0m         description\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(error),\n\u001b[0;32m    106\u001b[0m         status_code\u001b[38;5;241m=\u001b[39merror\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mstatus_code,\n\u001b[0;32m    107\u001b[0m         api_message\u001b[38;5;241m=\u001b[39mapi_message,\n\u001b[0;32m    108\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merror\u001b[39;00m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[0;32m    110\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPClientError(\n\u001b[0;32m    111\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError with server connection: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdeduct_api_key_from_string(\u001b[38;5;28mstr\u001b[39m(error))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    112\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merror\u001b[39;00m\n",
      "\u001b[1;31mHTTPCallErrorError\u001b[0m: HTTPCallErrorError(description='400 Client Error: Bad Request for url: https://detect.roboflow.com/digital-numbers-v3ajx/1?api_key=Zk***qg&disable_active_learning=False', api_message='Could not load input image. Cause: Malformed base64 input image.',status_code=400)"
     ]
    }
   ],
   "source": [
    "result = CLIENT.infer('mnist_train/000001.jpg', model_id=\"digital-numbers-v3ajx/1\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad50880",
   "metadata": {},
   "source": [
    "# model 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01732036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<roboflow.models.object_detection.ObjectDetectionModel at 0x2ee06e5c8b0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from roboflow import Roboflow\n",
    "import cv2\n",
    "\n",
    "rf = Roboflow(api_key=os.getenv('ROBOFLOW_API_KEY'))\n",
    "project = rf.workspace().project('numbers-yt0h2')\n",
    "numbers_model = project.version(2).model\n",
    "numbers_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18dc69ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'predictions': [{'x': 156, 'y': 236, 'width': 49, 'height': 41, 'confidence': 0.5040796995162964, 'class': '2', 'class_id': 2, 'detection_id': 'bf6c0020-ecaa-410b-b770-ee4ad5634314', 'image_path': 'mnist_train/000001.jpg', 'prediction_type': 'ObjectDetectionModel'}], 'image': {'width': '416', 'height': '416'}}\n",
      "156 236 49 41 2 0.5041\n"
     ]
    }
   ],
   "source": [
    "filename = 'mnist_train/000001.jpg'\n",
    "result = numbers_model.predict(filename, confidence=40, overlap=30)\n",
    "result_json = result.json()\n",
    "print(result_json)\n",
    "for pred in result_json[\"predictions\"]:\n",
    "    x = pred['x'] # 사각형의 중심위치 x\n",
    "    y = pred['y'] # 사각형의 중심위치 y\n",
    "    width = pred['width']\n",
    "    height = pred['height']\n",
    "    conf = pred['confidence']\n",
    "    cls = pred['class']\n",
    "    print(x, y, width, height, f'{cls} {conf:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a9c744",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "filename = 'mnist_train/000004.jpg'\n",
    "result = numbers_model.predict(filename, confidence=40, overlap=30)\n",
    "\n",
    "img = cv2.imread(filename)\n",
    "for pred in result:\n",
    "    x, y = pred['x'], pred['y']\n",
    "    width, height = pred['width'], pred['height']\n",
    "    conf = pred['confidence']\n",
    "    cls = pred['class']\n",
    "    \n",
    "    x1, y1 = int(x - width / 2), int(y - height / 2)\n",
    "    x2, y2 = int(x + width / 2), int(y + height / 2)\n",
    "    \n",
    "    cv2.rectangle(img, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "    cv2.putText(img, f'{cls} {conf:.4f}', (x1, y1), cv2.FONT_HERSHEY_PLAIN, 2, (0, 0, 255))\n",
    "\n",
    "cv2.imshow('image', img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5a0329",
   "metadata": {},
   "source": [
    "# 데이터 어노테이션 하기"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_cuda_yolo_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
