{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0678e649",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['John',\n",
       " 'likes',\n",
       " 'to',\n",
       " 'watch',\n",
       " 'movies',\n",
       " 'Mary',\n",
       " 'likes',\n",
       " 'movies',\n",
       " 'too',\n",
       " 'Mary',\n",
       " 'also',\n",
       " 'likes',\n",
       " 'to',\n",
       " 'watch',\n",
       " 'football',\n",
       " 'games']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"John likes to watch movies. Mary likes movies too.\\\n",
    " Mary also likes to watch football games.\"\n",
    "words = text.replace('.', '').split()\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a052e33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['John', 'Mary', 'also', 'football', 'games', 'likes', 'movies',\n",
       "        'to', 'too', 'watch'], dtype='<U8'),\n",
       " array([1, 2, 1, 1, 1, 3, 2, 2, 1, 2]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "word_count = np.unique(words, return_counts=True)\n",
    "word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "638c8f24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{np.str_('John'): np.int64(1),\n",
       " np.str_('Mary'): np.int64(2),\n",
       " np.str_('also'): np.int64(1),\n",
       " np.str_('football'): np.int64(1),\n",
       " np.str_('games'): np.int64(1),\n",
       " np.str_('likes'): np.int64(3),\n",
       " np.str_('movies'): np.int64(2),\n",
       " np.str_('to'): np.int64(2),\n",
       " np.str_('too'): np.int64(1),\n",
       " np.str_('watch'): np.int64(2)}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#딕셔너리 TF 생성\n",
    "word_to_cnt = {}\n",
    "for word, cnt in zip(*word_count):\n",
    "  word_to_cnt[word] = cnt\n",
    "  \n",
    "word_to_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f74886dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_cnt['movies']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "242b2dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    \"John likes to watch movies. Mary likes movies too.\",\n",
    "    \"Mary also likes to watch football games.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24e5409",
   "metadata": {},
   "source": [
    "# TDM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4974b06c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 1, 2, 1, 2, 1, 1, 1],\n",
       "       [1, 1, 1, 0, 1, 1, 0, 1, 0, 1]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vector = CountVectorizer()\n",
    "dtm_array = vector.fit_transform(corpus).toarray()\n",
    "dtm_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "690b80d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'john': 3, 'likes': 4, 'to': 7, 'watch': 9, 'movies': 6, 'mary': 5, 'too': 8, 'also': 0, 'football': 1, 'games': 2}\n"
     ]
    }
   ],
   "source": [
    "print(vector.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eddc2336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 1 2 1 2 1 1 1]\n",
      " [1 1 1 0 1 1 0 1 0 1]]\n",
      "{'john': 3, 'likes': 4, 'to': 7, 'watch': 9, 'movies': 6, 'mary': 5, 'too': 8, 'also': 0, 'football': 1, 'games': 2}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vector = CountVectorizer()\n",
    "tdm_array = vector.fit_transform(corpus).toarray()\n",
    "tf_dic = vector.vocabulary_\n",
    "print(tdm_array)\n",
    "print(tf_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "750260e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>also</th>\n",
       "      <th>football</th>\n",
       "      <th>games</th>\n",
       "      <th>john</th>\n",
       "      <th>likes</th>\n",
       "      <th>mary</th>\n",
       "      <th>movies</th>\n",
       "      <th>to</th>\n",
       "      <th>too</th>\n",
       "      <th>watch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   also  football  games  john  likes  mary  movies  to  too  watch\n",
       "0     0         0      0     1      2     1       2   1    1      1\n",
       "1     1         1      1     0      1     1       0   1    0      1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "tf_dic_sorted = dict(sorted(tf_dic.items(), key=lambda item : item[1]))\n",
    "tf_dic_sorted\n",
    "\n",
    "pd.DataFrame(dtm_array, columns=tf_dic_sorted.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dea9305",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3f8b3e71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>also</th>\n",
       "      <th>football</th>\n",
       "      <th>games</th>\n",
       "      <th>john</th>\n",
       "      <th>likes</th>\n",
       "      <th>mary</th>\n",
       "      <th>movies</th>\n",
       "      <th>to</th>\n",
       "      <th>too</th>\n",
       "      <th>watch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.323699</td>\n",
       "      <td>0.460629</td>\n",
       "      <td>0.230315</td>\n",
       "      <td>0.647398</td>\n",
       "      <td>0.230315</td>\n",
       "      <td>0.323699</td>\n",
       "      <td>0.230315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.446101</td>\n",
       "      <td>0.446101</td>\n",
       "      <td>0.446101</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.317404</td>\n",
       "      <td>0.317404</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.317404</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.317404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       also  football     games      john     likes      mary    movies  \\\n",
       "0  0.000000  0.000000  0.000000  0.323699  0.460629  0.230315  0.647398   \n",
       "1  0.446101  0.446101  0.446101  0.000000  0.317404  0.317404  0.000000   \n",
       "\n",
       "         to       too     watch  \n",
       "0  0.230315  0.323699  0.230315  \n",
       "1  0.317404  0.000000  0.317404  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "# TfidfVectorizer 객체 생성\n",
    "tfidf_vec = TfidfVectorizer()\n",
    "\n",
    "# fit_transform을 사용하여 텍스트 데이터를 TF-IDF 행렬로 변환\n",
    "tfidf_array = tfidf_vec.fit_transform(corpus).toarray()\n",
    "# print(tfidf_array)\n",
    "\n",
    "# 단어 사전 (vocabulary_)을 사용하여 단어와 인덱스 매핑\n",
    "tfidf_dic = tfidf_vec.vocabulary_\n",
    "# print(tfidf_dic)\n",
    "\n",
    "# 단어 사전 (tfidf_dic)을 TF-IDF 값(item[1])을 기준으로 정렬\n",
    "# lambda 함수는 정렬의 기준(key)을 설정하며, item[1]은 딕셔너리의 값(value)을 의미\n",
    "tfidf_dic_sorted = dict(sorted(tfidf_dic.items(), key=lambda item: item[1]))\n",
    "# print(tfidf_dic_sorted)\n",
    "\n",
    "# TF-IDF 행렬을 DataFrame으로 변환\n",
    "# columns는 정렬된 단어 사전의 키(단어)를 사용\n",
    "tfidf_dtm = pd.DataFrame(tfidf_array, columns=tfidf_dic_sorted.keys())\n",
    "# print(tfidf_dtm)\n",
    "\n",
    "# 결과 출력\n",
    "tfidf_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ddd31b42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.32369906, 0.46062909,\n",
       "        0.23031454, 0.64739811, 0.23031454, 0.32369906, 0.23031454],\n",
       "       [0.44610081, 0.44610081, 0.44610081, 0.        , 0.3174044 ,\n",
       "        0.3174044 , 0.        , 0.3174044 , 0.        , 0.3174044 ]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "50f40690",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'john': 3,\n",
       " 'likes': 4,\n",
       " 'to': 7,\n",
       " 'watch': 9,\n",
       " 'movies': 6,\n",
       " 'mary': 5,\n",
       " 'too': 8,\n",
       " 'also': 0,\n",
       " 'football': 1,\n",
       " 'games': 2}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "53d6f12e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'also': 0,\n",
       " 'football': 1,\n",
       " 'games': 2,\n",
       " 'john': 3,\n",
       " 'likes': 4,\n",
       " 'mary': 5,\n",
       " 'movies': 6,\n",
       " 'to': 7,\n",
       " 'too': 8,\n",
       " 'watch': 9}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_dic_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6329ecc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>also</th>\n",
       "      <th>football</th>\n",
       "      <th>games</th>\n",
       "      <th>john</th>\n",
       "      <th>likes</th>\n",
       "      <th>mary</th>\n",
       "      <th>movies</th>\n",
       "      <th>to</th>\n",
       "      <th>too</th>\n",
       "      <th>watch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.323699</td>\n",
       "      <td>0.460629</td>\n",
       "      <td>0.230315</td>\n",
       "      <td>0.647398</td>\n",
       "      <td>0.230315</td>\n",
       "      <td>0.323699</td>\n",
       "      <td>0.230315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.446101</td>\n",
       "      <td>0.446101</td>\n",
       "      <td>0.446101</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.317404</td>\n",
       "      <td>0.317404</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.317404</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.317404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       also  football     games      john     likes      mary    movies  \\\n",
       "0  0.000000  0.000000  0.000000  0.323699  0.460629  0.230315  0.647398   \n",
       "1  0.446101  0.446101  0.446101  0.000000  0.317404  0.317404  0.000000   \n",
       "\n",
       "         to       too     watch  \n",
       "0  0.230315  0.323699  0.230315  \n",
       "1  0.317404  0.000000  0.317404  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6f11a7a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-4.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.2 kB)\n",
      "Collecting numpy<2.0,>=1.18.5 (from gensim)\n",
      "  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Collecting scipy<1.14.0,>=1.7.0 (from gensim)\n",
      "  Downloading scipy-1.13.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "Collecting smart-open>=1.8.1 (from gensim)\n",
      "  Downloading smart_open-7.3.0.post1-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: wrapt in /home/devuser/miniconda3/envs/tf_cuda_env/lib/python3.10/site-packages (from smart-open>=1.8.1->gensim) (1.17.3)\n",
      "Downloading gensim-4.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.5/26.5 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m  \u001b[33m0:00:06\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m  \u001b[33m0:00:05\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.13.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m  \u001b[33m0:00:11\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading smart_open-7.3.0.post1-py3-none-any.whl (61 kB)\n",
      "Installing collected packages: smart-open, numpy, scipy, gensim\n",
      "\u001b[2K  Attempting uninstall: numpy\n",
      "\u001b[2K    Found existing installation: numpy 2.2.6\n",
      "\u001b[2K    Uninstalling numpy-2.2.6:\n",
      "\u001b[2K      Successfully uninstalled numpy-2.2.6\n",
      "\u001b[2K  Attempting uninstall: scipy[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/4\u001b[0m [numpy]\n",
      "\u001b[2K    Found existing installation: scipy 1.15.3━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/4\u001b[0m [numpy]\n",
      "\u001b[2K    Uninstalling scipy-1.15.3:90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/4\u001b[0m [numpy]\n",
      "\u001b[2K      Successfully uninstalled scipy-1.15.3━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/4\u001b[0m [numpy]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4/4\u001b[0m [gensim]2m3/4\u001b[0m [gensim]\n",
      "\u001b[1A\u001b[2KSuccessfully installed gensim-4.3.3 numpy-1.26.4 scipy-1.13.1 smart-open-7.3.0.post1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d917ff8a",
   "metadata": {},
   "source": [
    "kernal restart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "650322b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d4ad8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    \"John likes to watch movies. Mary likes movies too.\",\n",
    "    \"Mary also likes to watch football games.\"\n",
    "]\n",
    "word_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abba6f8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['John', 'likes', 'to', 'watch', 'movies', 'Mary', 'likes', 'movies', 'too'],\n",
       " ['Mary', 'also', 'likes', 'to', 'watch', 'football', 'games'],\n",
       " ['John', 'likes', 'to', 'watch', 'movies', 'Mary', 'likes', 'movies', 'too'],\n",
       " ['Mary', 'also', 'likes', 'to', 'watch', 'football', 'games']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for word in corpus:\n",
    "    word_list.append(word.replace('.','').split())\n",
    "\n",
    "word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83752427",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('John', 0.1716582030057907),\n",
       " ('also', 0.06598272919654846),\n",
       " ('Mary', 0.00861525908112526),\n",
       " ('watch', -0.06767924129962921),\n",
       " ('games', -0.08545631915330887),\n",
       " ('football', -0.08945832401514053),\n",
       " ('too', -0.11875486373901367),\n",
       " ('to', -0.13642998039722443)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Word2Vec(word_list, sg=0, vector_size=100, window=3, min_count=1)\n",
    "model.wv.most_similar('likes', 'movies')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02839e82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('likes', 0.15334244072437286),\n",
       " ('football', 0.07839599251747131),\n",
       " ('also', 0.015081927180290222),\n",
       " ('too', 0.007014104165136814),\n",
       " ('movies', -0.006439352408051491),\n",
       " ('games', -0.07737728208303452),\n",
       " ('to', -0.12004965543746948),\n",
       " ('watch', -0.16034363210201263)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('John','Mary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a555ba68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('to', 0.13887983560562134),\n",
       " ('watch', 0.13149002194404602),\n",
       " ('movies', 0.06409990042448044),\n",
       " ('too', 0.06059820577502251),\n",
       " ('football', 0.019152285531163216),\n",
       " ('Mary', 0.009408489800989628),\n",
       " ('also', -0.05774582177400589),\n",
       " ('likes', -0.05987628549337387),\n",
       " ('John', -0.10513809323310852)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('games')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f59fee4",
   "metadata": {},
   "source": [
    "# 실습 - 영화평 분류하기( imdb 데이터셋 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e1cf90e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "\u001b[1m17464789/17464789\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((array([list([1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]),\n",
       "         list([1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 2, 4, 1153, 9, 194, 775, 7, 8255, 2, 349, 2637, 148, 605, 2, 8003, 15, 123, 125, 68, 2, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 2, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 2, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 2, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]),\n",
       "         list([1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 5974, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2401, 311, 12, 16, 3711, 33, 75, 43, 1829, 296, 4, 86, 320, 35, 534, 19, 263, 4821, 1301, 4, 1873, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 1716, 43, 645, 662, 8, 257, 85, 1200, 42, 1228, 2578, 83, 68, 3912, 15, 36, 165, 1539, 278, 36, 69, 2, 780, 8, 106, 14, 6905, 1338, 18, 6, 22, 12, 215, 28, 610, 40, 6, 87, 326, 23, 2300, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2307, 51, 9, 170, 23, 595, 116, 595, 1352, 13, 191, 79, 638, 89, 2, 14, 9, 8, 106, 607, 624, 35, 534, 6, 227, 7, 129, 113]),\n",
       "         ...,\n",
       "         list([1, 11, 6, 230, 245, 6401, 9, 6, 1225, 446, 2, 45, 2174, 84, 8322, 4007, 21, 4, 912, 84, 2, 325, 725, 134, 2, 1715, 84, 5, 36, 28, 57, 1099, 21, 8, 140, 8, 703, 5, 2, 84, 56, 18, 1644, 14, 9, 31, 7, 4, 9406, 1209, 2295, 2, 1008, 18, 6, 20, 207, 110, 563, 12, 8, 2901, 2, 8, 97, 6, 20, 53, 4767, 74, 4, 460, 364, 1273, 29, 270, 11, 960, 108, 45, 40, 29, 2961, 395, 11, 6, 4065, 500, 7, 2, 89, 364, 70, 29, 140, 4, 64, 4780, 11, 4, 2678, 26, 178, 4, 529, 443, 2, 5, 27, 710, 117, 2, 8123, 165, 47, 84, 37, 131, 818, 14, 595, 10, 10, 61, 1242, 1209, 10, 10, 288, 2260, 1702, 34, 2901, 2, 4, 65, 496, 4, 231, 7, 790, 5, 6, 320, 234, 2766, 234, 1119, 1574, 7, 496, 4, 139, 929, 2901, 2, 7750, 5, 4241, 18, 4, 8497, 2, 250, 11, 1818, 7561, 4, 4217, 5408, 747, 1115, 372, 1890, 1006, 541, 9303, 7, 4, 59, 2, 4, 3586, 2]),\n",
       "         list([1, 1446, 7079, 69, 72, 3305, 13, 610, 930, 8, 12, 582, 23, 5, 16, 484, 685, 54, 349, 11, 4120, 2959, 45, 58, 1466, 13, 197, 12, 16, 43, 23, 2, 5, 62, 30, 145, 402, 11, 4131, 51, 575, 32, 61, 369, 71, 66, 770, 12, 1054, 75, 100, 2198, 8, 4, 105, 37, 69, 147, 712, 75, 3543, 44, 257, 390, 5, 69, 263, 514, 105, 50, 286, 1814, 23, 4, 123, 13, 161, 40, 5, 421, 4, 116, 16, 897, 13, 2, 40, 319, 5872, 112, 6700, 11, 4803, 121, 25, 70, 3468, 4, 719, 3798, 13, 18, 31, 62, 40, 8, 7200, 4, 2, 7, 14, 123, 5, 942, 25, 8, 721, 12, 145, 5, 202, 12, 160, 580, 202, 12, 6, 52, 58, 2, 92, 401, 728, 12, 39, 14, 251, 8, 15, 251, 5, 2, 12, 38, 84, 80, 124, 12, 9, 23]),\n",
       "         list([1, 17, 6, 194, 337, 7, 4, 204, 22, 45, 254, 8, 106, 14, 123, 4, 2, 270, 2, 5, 2, 2, 732, 2098, 101, 405, 39, 14, 1034, 4, 1310, 9, 115, 50, 305, 12, 47, 4, 168, 5, 235, 7, 38, 111, 699, 102, 7, 4, 4039, 9245, 9, 24, 6, 78, 1099, 17, 2345, 2, 21, 27, 9685, 6139, 5, 2, 1603, 92, 1183, 4, 1310, 7, 4, 204, 42, 97, 90, 35, 221, 109, 29, 127, 27, 118, 8, 97, 12, 157, 21, 6789, 2, 9, 6, 66, 78, 1099, 4, 631, 1191, 5, 2642, 272, 191, 1070, 6, 7585, 8, 2197, 2, 2, 544, 5, 383, 1271, 848, 1468, 2, 497, 2, 8, 1597, 8778, 2, 21, 60, 27, 239, 9, 43, 8368, 209, 405, 10, 10, 12, 764, 40, 4, 248, 20, 12, 16, 5, 174, 1791, 72, 7, 51, 6, 1739, 22, 4, 204, 131, 9])],\n",
       "        dtype=object),\n",
       "  array([1, 0, 0, ..., 0, 1, 0])),\n",
       " (array([list([1, 591, 202, 14, 31, 6, 717, 10, 10, 2, 2, 5, 4, 360, 7, 4, 177, 5760, 394, 354, 4, 123, 9, 1035, 1035, 1035, 10, 10, 13, 92, 124, 89, 488, 7944, 100, 28, 1668, 14, 31, 23, 27, 7479, 29, 220, 468, 8, 124, 14, 286, 170, 8, 157, 46, 5, 27, 239, 16, 179, 2, 38, 32, 25, 7944, 451, 202, 14, 6, 717]),\n",
       "         list([1, 14, 22, 3443, 6, 176, 7, 5063, 88, 12, 2679, 23, 1310, 5, 109, 943, 4, 114, 9, 55, 606, 5, 111, 7, 4, 139, 193, 273, 23, 4, 172, 270, 11, 7216, 2, 4, 8463, 2801, 109, 1603, 21, 4, 22, 3861, 8, 6, 1193, 1330, 10, 10, 4, 105, 987, 35, 841, 2, 19, 861, 1074, 5, 1987, 2, 45, 55, 221, 15, 670, 5304, 526, 14, 1069, 4, 405, 5, 2438, 7, 27, 85, 108, 131, 4, 5045, 5304, 3884, 405, 9, 3523, 133, 5, 50, 13, 104, 51, 66, 166, 14, 22, 157, 9, 4, 530, 239, 34, 8463, 2801, 45, 407, 31, 7, 41, 3778, 105, 21, 59, 299, 12, 38, 950, 5, 4521, 15, 45, 629, 488, 2733, 127, 6, 52, 292, 17, 4, 6936, 185, 132, 1988, 5304, 1799, 488, 2693, 47, 6, 392, 173, 4, 2, 4378, 270, 2352, 4, 1500, 7, 4, 65, 55, 73, 11, 346, 14, 20, 9, 6, 976, 2078, 7, 5293, 861, 2, 5, 4182, 30, 3127, 2, 56, 4, 841, 5, 990, 692, 8, 4, 1669, 398, 229, 10, 10, 13, 2822, 670, 5304, 14, 9, 31, 7, 27, 111, 108, 15, 2033, 19, 7836, 1429, 875, 551, 14, 22, 9, 1193, 21, 45, 4829, 5, 45, 252, 8, 2, 6, 565, 921, 3639, 39, 4, 529, 48, 25, 181, 8, 67, 35, 1732, 22, 49, 238, 60, 135, 1162, 14, 9, 290, 4, 58, 10, 10, 472, 45, 55, 878, 8, 169, 11, 374, 5687, 25, 203, 28, 8, 818, 12, 125, 4, 3077]),\n",
       "         list([1, 111, 748, 4368, 1133, 2, 2, 4, 87, 1551, 1262, 7, 31, 318, 9459, 7, 4, 498, 5076, 748, 63, 29, 5161, 220, 686, 2, 5, 17, 12, 575, 220, 2507, 17, 6, 185, 132, 2, 16, 53, 928, 11, 2, 74, 4, 438, 21, 27, 2, 589, 8, 22, 107, 2, 2, 997, 1638, 8, 35, 2076, 9019, 11, 22, 231, 54, 29, 1706, 29, 100, 2, 2425, 34, 2, 8738, 2, 5, 2, 98, 31, 2122, 33, 6, 58, 14, 3808, 1638, 8, 4, 365, 7, 2789, 3761, 356, 346, 4, 2, 1060, 63, 29, 93, 11, 5421, 11, 2, 33, 6, 58, 54, 1270, 431, 748, 7, 32, 2580, 16, 11, 94, 2, 10, 10, 4, 993, 2, 7, 4, 1766, 2634, 2164, 2, 8, 847, 8, 1450, 121, 31, 7, 27, 86, 2663, 2, 16, 6, 465, 993, 2006, 2, 573, 17, 2, 42, 4, 2, 37, 473, 6, 711, 6, 8869, 7, 328, 212, 70, 30, 258, 11, 220, 32, 7, 108, 21, 133, 12, 9, 55, 465, 849, 3711, 53, 33, 2071, 1969, 37, 70, 1144, 4, 5940, 1409, 74, 476, 37, 62, 91, 1329, 169, 4, 1330, 2, 146, 655, 2212, 5, 258, 12, 184, 2, 546, 5, 849, 2, 7, 4, 22, 1436, 18, 631, 1386, 797, 7, 4, 8712, 71, 348, 425, 4320, 1061, 19, 2, 5, 2, 11, 661, 8, 339, 2, 4, 2455, 2, 7, 4, 1962, 10, 10, 263, 787, 9, 270, 11, 6, 9466, 4, 2, 2, 121, 4, 5437, 26, 4434, 19, 68, 1372, 5, 28, 446, 6, 318, 7149, 8, 67, 51, 36, 70, 81, 8, 4392, 2294, 36, 1197, 8, 2, 2, 18, 6, 711, 4, 9909, 26, 2, 1125, 11, 14, 636, 720, 12, 426, 28, 77, 776, 8, 97, 38, 111, 7489, 6175, 168, 1239, 5189, 137, 2, 18, 27, 173, 9, 2399, 17, 6, 2, 428, 2, 232, 11, 4, 8014, 37, 272, 40, 2708, 247, 30, 656, 6, 2, 54, 2, 3292, 98, 6, 2840, 40, 558, 37, 6093, 98, 4, 2, 1197, 15, 14, 9, 57, 4893, 5, 4659, 6, 275, 711, 7937, 2, 3292, 98, 6, 2, 10, 10, 6639, 19, 14, 2, 267, 162, 711, 37, 5900, 752, 98, 4, 2, 2378, 90, 19, 6, 2, 7, 2, 1810, 2, 4, 4770, 3183, 930, 8, 508, 90, 4, 1317, 8, 4, 2, 17, 2, 3965, 1853, 4, 1494, 8, 4468, 189, 4, 2, 6287, 5774, 4, 4770, 5, 95, 271, 23, 6, 7742, 6063, 2, 5437, 33, 1526, 6, 425, 3155, 2, 4535, 1636, 7, 4, 4669, 2, 469, 4, 4552, 54, 4, 150, 5664, 2, 280, 53, 2, 2, 18, 339, 29, 1978, 27, 7885, 5, 2, 68, 1830, 19, 6571, 2, 4, 1515, 7, 263, 65, 2132, 34, 6, 5680, 7489, 43, 159, 29, 9, 4706, 9, 387, 73, 195, 584, 10, 10, 1069, 4, 58, 810, 54, 14, 6078, 117, 22, 16, 93, 5, 1069, 4, 192, 15, 12, 16, 93, 34, 6, 1766, 2, 33, 4, 5673, 7, 15, 2, 9252, 3286, 325, 12, 62, 30, 776, 8, 67, 14, 17, 6, 2, 44, 148, 687, 2, 203, 42, 203, 24, 28, 69, 2, 6676, 11, 330, 54, 29, 93, 2, 21, 845, 2, 27, 1099, 7, 819, 4, 22, 1407, 17, 6, 2, 787, 7, 2460, 2, 2, 100, 30, 4, 3737, 3617, 3169, 2321, 42, 1898, 11, 4, 3814, 42, 101, 704, 7, 101, 999, 15, 1625, 94, 2926, 180, 5, 9, 9101, 34, 2, 45, 6, 1429, 22, 60, 6, 1220, 31, 11, 94, 6408, 96, 21, 94, 749, 9, 57, 975]),\n",
       "         ...,\n",
       "         list([1, 13, 1408, 15, 8, 135, 14, 9, 35, 32, 46, 394, 20, 62, 30, 5093, 21, 45, 184, 78, 4, 1492, 910, 769, 2290, 2515, 395, 4257, 5, 1454, 11, 119, 2, 89, 1036, 4, 116, 218, 78, 21, 407, 100, 30, 128, 262, 15, 7, 185, 2280, 284, 1842, 2, 37, 315, 4, 226, 20, 272, 2942, 40, 29, 152, 60, 181, 8, 30, 50, 553, 362, 80, 119, 12, 21, 846, 5518]),\n",
       "         list([1, 11, 119, 241, 9, 4, 840, 20, 12, 468, 15, 94, 3684, 562, 791, 39, 4, 86, 107, 8, 97, 14, 31, 33, 4, 2960, 7, 743, 46, 1028, 9, 3531, 5, 4, 768, 47, 8, 79, 90, 145, 164, 162, 50, 6, 501, 119, 7, 9, 4, 78, 232, 15, 16, 224, 11, 4, 333, 20, 4, 985, 200, 5, 2, 5, 9, 1861, 8, 79, 357, 4, 20, 47, 220, 57, 206, 139, 11, 12, 5, 55, 117, 212, 13, 1276, 92, 124, 51, 45, 1188, 71, 536, 13, 520, 14, 20, 6, 2302, 7, 470]),\n",
       "         list([1, 6, 52, 7465, 430, 22, 9, 220, 2594, 8, 28, 2, 519, 3227, 6, 769, 15, 47, 6, 3482, 4067, 8, 114, 5, 33, 222, 31, 55, 184, 704, 5586, 2, 19, 346, 3153, 5, 6, 364, 350, 4, 184, 5586, 9, 133, 1810, 11, 5417, 2, 21, 4, 7298, 2, 570, 50, 2005, 2643, 9, 6, 1249, 17, 6, 2, 2, 21, 17, 6, 1211, 232, 1138, 2249, 29, 266, 56, 96, 346, 194, 308, 9, 194, 21, 29, 218, 1078, 19, 4, 78, 173, 7, 27, 2, 5698, 3406, 718, 2, 9, 6, 6907, 17, 210, 5, 3281, 5677, 47, 77, 395, 14, 172, 173, 18, 2740, 2931, 4517, 82, 127, 27, 173, 11, 6, 392, 217, 21, 50, 9, 57, 65, 12, 2, 53, 40, 35, 390, 7, 11, 4, 3567, 7, 4, 314, 74, 6, 792, 22, 2, 19, 714, 727, 5205, 382, 4, 91, 6533, 439, 19, 14, 20, 9, 1441, 5805, 1118, 4, 756, 25, 124, 4, 31, 12, 16, 93, 804, 34, 2005, 2643])],\n",
       "        dtype=object),\n",
       "  array([0, 1, 1, ..., 0, 0, 0])))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import imdb\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words = 10000)\n",
    "(X_train, y_train), (X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65957a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  train, test 데이터 전처리\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "X_train_pad = pad_sequences(X_train, maxlen=80, padding='post', truncating='post')\n",
    "X_test_pad = pad_sequences(X_test, maxlen=80, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bc7630",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1756966471.915064   11386 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5563 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">320,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2560</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">163,904</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_5 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │       \u001b[38;5;34m320,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2560\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │       \u001b[38;5;34m163,904\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │           \u001b[38;5;34m130\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">484,034</span> (1.85 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m484,034\u001b[0m (1.85 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">484,034</span> (1.85 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m484,034\u001b[0m (1.85 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# dnn\n",
    "from tensorflow.keras import Sequential, layers\n",
    "\n",
    "model_dnn=Sequential(\n",
    "    [\n",
    "    layers.Input(shape=(80,)),\n",
    "    layers.Embedding(input_dim=10000, output_dim=32), # (80,32) 행렬\n",
    "    layers.Flatten(), # 1차원으로 평탄화\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(2, activation='softmax')\n",
    "    ]\n",
    ")\n",
    "\n",
    "model_dnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d35ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-04 15:24:43.153239: I external/local_xla/xla/service/service.cc:163] XLA service 0x7fbac80063f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-04 15:24:43.153267: I external/local_xla/xla/service/service.cc:171]   StreamExecutor device (0): NVIDIA GeForce RTX 4060 Laptop GPU, Compute Capability 8.9\n",
      "2025-09-04 15:24:43.185502: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-04 15:24:43.298461: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:473] Loaded cuDNN version 91200\n",
      "2025-09-04 15:24:47.152390: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_117', 124 bytes spill stores, 124 bytes spill loads\n",
      "\n",
      "2025-09-04 15:24:47.169651: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_292', 24 bytes spill stores, 24 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 41/125\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5178 - loss: 0.6918"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1756967088.745007   15698 device_compiler.h:196] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.6836 - loss: 0.5694\n",
      "Epoch 2/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8818 - loss: 0.2857\n",
      "Epoch 3/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9796 - loss: 0.0855\n",
      "Epoch 4/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9986 - loss: 0.0150\n",
      "Epoch 5/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9997 - loss: 0.0044\n",
      "Epoch 6/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0019\n",
      "Epoch 7/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0012\n",
      "Epoch 8/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 8.0223e-04\n",
      "Epoch 9/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 5.9241e-04\n",
      "Epoch 10/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 4.5669e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7fbbc3bd5ea0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dnn \n",
    "model_dnn.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model_dnn.fit(X_train_pad, y_train, epochs=10, batch_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1372393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7798 - loss: 0.9074\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9073679447174072, 0.7797600030899048]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dnn\n",
    "dnn_loss, dnn_accuracy = model_dnn.evaluate(X_test_pad, y_test)\n",
    "print(f\"Loss: {dnn_loss:.4f}, Accuacy : {dnn_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "92c07dd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">320,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ simple_rnn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_6 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │       \u001b[38;5;34m320,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ simple_rnn (\u001b[38;5;33mSimpleRNN\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m6,208\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │           \u001b[38;5;34m130\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">326,338</span> (1.24 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m326,338\u001b[0m (1.24 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">326,338</span> (1.24 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m326,338\u001b[0m (1.24 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# RNN 모델\n",
    "from tensorflow.keras import Sequential, layers\n",
    "\n",
    "model_rnn=Sequential(\n",
    "    [\n",
    "    layers.Input(shape=(80,)),\n",
    "    layers.Embedding(input_dim=10000, output_dim=32), # (80,32) 행렬\n",
    "    # layers.Flatten(), # 1차원으로 평탄화\n",
    "    # layers.Dense(64, activation='relu'),\n",
    "    layers.SimpleRNN(64),\n",
    "    layers.Dense(2, activation='softmax')\n",
    "    ]\n",
    ")\n",
    "\n",
    "model_rnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c1d0695d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-04 15:27:39.506860: I external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.\n",
      "2025-09-04 15:27:39.506920: I external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.\n",
      "2025-09-04 15:27:39.506938: I external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.\n",
      "2025-09-04 15:27:42.037806: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_29', 36 bytes spill stores, 36 bytes spill loads\n",
      "\n",
      "2025-09-04 15:27:42.856238: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_29', 200 bytes spill stores, 200 bytes spill loads\n",
      "\n",
      "2025-09-04 15:27:44.867911: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_30', 16 bytes spill stores, 16 bytes spill loads\n",
      "\n",
      "2025-09-04 15:27:45.309698: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_28', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2025-09-04 15:27:45.381023: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_30', 528 bytes spill stores, 528 bytes spill loads\n",
      "\n",
      "2025-09-04 15:27:45.654267: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_28', 360 bytes spill stores, 360 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 28ms/step - accuracy: 0.5166 - loss: 0.6934\n",
      "Epoch 2/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 28ms/step - accuracy: 0.7661 - loss: 0.4969\n",
      "Epoch 3/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 0.8944 - loss: 0.2702\n",
      "Epoch 4/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 0.9582 - loss: 0.1196\n",
      "Epoch 5/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 29ms/step - accuracy: 0.9898 - loss: 0.0401\n",
      "Epoch 6/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 28ms/step - accuracy: 0.9940 - loss: 0.0263\n",
      "Epoch 7/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 29ms/step - accuracy: 0.9956 - loss: 0.0186\n",
      "Epoch 8/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 28ms/step - accuracy: 0.9908 - loss: 0.0288\n",
      "Epoch 9/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 28ms/step - accuracy: 0.9969 - loss: 0.0130\n",
      "Epoch 10/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 29ms/step - accuracy: 0.9990 - loss: 0.0059\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7fbbc517b190>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rnn 모델 compile\n",
    "model_rnn.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model_rnn.fit(X_train_pad, y_train, epochs=10, batch_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886f85c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7490 - loss: 1.1472\n",
      "Loss: 1.1472, Accuacy : 0.7490\n"
     ]
    }
   ],
   "source": [
    "# evaluate\n",
    "rnn_loss, rnn_accuracy = model_rnn.evaluate(X_test_pad, y_test)\n",
    "print(f\"Loss: {rnn_loss:.4f}, Accuacy : {rnn_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757fb2b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e3219ce9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">320,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ simple_rnn_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ simple_rnn_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">258</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_7 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │       \u001b[38;5;34m320,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ simple_rnn_1 (\u001b[38;5;33mSimpleRNN\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │         \u001b[38;5;34m6,208\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ simple_rnn_2 (\u001b[38;5;33mSimpleRNN\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m24,704\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │           \u001b[38;5;34m258\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">351,170</span> (1.34 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m351,170\u001b[0m (1.34 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">351,170</span> (1.34 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m351,170\u001b[0m (1.34 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# RNN 모델 2\n",
    "from tensorflow.keras import Sequential, layers\n",
    "\n",
    "model_rnn_2=Sequential(\n",
    "    [\n",
    "    layers.Input(shape=(80,)),\n",
    "    layers.Embedding(input_dim=10000, output_dim=32), # (80,32) 행렬\n",
    "    # layers.Flatten(), # 1차원으로 평탄화\n",
    "    # layers.Dense(64, activation='relu'),\n",
    "    layers.SimpleRNN(64, return_sequences=True),\n",
    "    layers.SimpleRNN(128),\n",
    "    layers.Dense(2, activation='softmax')\n",
    "    ]\n",
    ")\n",
    "\n",
    "model_rnn_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340f76a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 48ms/step - accuracy: 0.9936 - loss: 0.0183\n",
      "Epoch 2/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 48ms/step - accuracy: 0.9977 - loss: 0.0086\n",
      "Epoch 3/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 48ms/step - accuracy: 0.9983 - loss: 0.0058\n",
      "Epoch 4/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 44ms/step - accuracy: 0.9943 - loss: 0.0163\n",
      "Epoch 5/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.9958 - loss: 0.0122\n",
      "Epoch 6/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.9966 - loss: 0.0106\n",
      "Epoch 7/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 44ms/step - accuracy: 0.9966 - loss: 0.0111\n",
      "Epoch 8/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - accuracy: 0.9977 - loss: 0.0078\n",
      "Epoch 9/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.9983 - loss: 0.0050\n",
      "Epoch 10/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 44ms/step - accuracy: 0.9988 - loss: 0.0035\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.7184 - loss: 2.0934\n",
      "Loss: 2.0934, Accuacy : 0.7184\n"
     ]
    }
   ],
   "source": [
    "# rnn_2 모델 compile\n",
    "model_rnn_2.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model_rnn_2.fit(X_train_pad, y_train, epochs=10, batch_size=200)\n",
    "# evaluate\n",
    "rnn_2_loss, rnn_2_accuracy = model_rnn_2.evaluate(X_test_pad, y_test)\n",
    "print(f\"Loss: {rnn_2_loss:.4f}, Accuacy : {rnn_2_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "759985bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 53ms/step - accuracy: 0.5038 - loss: 0.7001\n",
      "Epoch 2/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 49ms/step - accuracy: 0.5076 - loss: 0.6953\n",
      "Epoch 3/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.5120 - loss: 0.6945\n",
      "Epoch 4/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - accuracy: 0.5079 - loss: 0.6942\n",
      "Epoch 5/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - accuracy: 0.5170 - loss: 0.6928\n",
      "Epoch 6/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 54ms/step - accuracy: 0.5170 - loss: 0.6928\n",
      "Epoch 7/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 44ms/step - accuracy: 0.5198 - loss: 0.6916\n",
      "Epoch 8/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.5286 - loss: 0.6910\n",
      "Epoch 9/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.5307 - loss: 0.6907\n",
      "Epoch 10/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.5326 - loss: 0.6901\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.5080 - loss: 0.6958\n",
      "Loss: 0.6958, Accuacy : 0.5080\n"
     ]
    }
   ],
   "source": [
    "# RNN 모델 3\n",
    "from tensorflow.keras import Sequential, layers\n",
    "\n",
    "model_rnn_3=Sequential(\n",
    "    [\n",
    "    layers.Input(shape=(80,)),\n",
    "    layers.Embedding(input_dim=10000, output_dim=32), # (80,32) 행렬\n",
    "    # layers.Flatten(), # 1차원으로 평탄화\n",
    "    # layers.Dense(64, activation='relu'),\n",
    "    layers.SimpleRNN(64, return_sequences=True),\n",
    "    layers.SimpleRNN(128),\n",
    "    layers.Dense(2, activation='softmax')\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# rnn 모델 compile\n",
    "model_rnn_3.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model_rnn_3.fit(X_train_pad, y_train, epochs=10, batch_size=200)\n",
    "# evaluate\n",
    "rnn_3_loss, rnn_3_accuracy = model_rnn_3.evaluate(X_test_pad, y_test)\n",
    "print(f\"Loss: {rnn_3_loss:.4f}, Accuacy : {rnn_3_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19959564",
   "metadata": {},
   "source": [
    "dnn : Loss : 0.9073, Accuacy: 0.7797 # DNN   \n",
    "rnn : Loss: 1.1472, Accuacy : 0.7490 # RNN\n",
    "\n",
    "rnn_2 : Loss: 2.0934, Accuacy : 0.7184 # layers.SimpleRNN(128)  과대적합"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880b5610",
   "metadata": {},
   "source": [
    "0. 비교군 : Loss: 3.0997, Accuacy : 0.5097   \n",
    "1. 옵티마지어 sgd : Loss: 0.6958, Accuacy : 0.5080 # optimizer : sgd     \n",
    "2. 전체 단어의 개수 1000 : Loss: 0.9225, Accuacy : 0.7269    \n",
    "3. 영화평의 길이를 200개로 바꾸기 : Loss: 0.6928, Accuacy : 0.5038    \n",
    "4. pad_sequence의 truncating과 padding을 pre로 바꾸기 : Loss: 1.2778, Accuacy : 0.7986 # 과대적합   \n",
    "5. RNN 층(뉴런 128개)을 하나 더 추가 : Loss: 0.5368, Accuacy : 0.7324   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a886c3",
   "metadata": {},
   "source": [
    "# 비교군 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fa0f5779",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import imdb\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words = 10000)\n",
    "(X_train, y_train), (X_test, y_test)\n",
    "\n",
    "#  train, test 데이터 전처리\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "X_train_pad = pad_sequences(X_train, maxlen=80, padding='post', truncating='post')\n",
    "X_test_pad = pad_sequences(X_test, maxlen=80, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6c1af1de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 44ms/step - accuracy: 0.5015 - loss: 0.6995\n",
      "Epoch 2/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - accuracy: 0.5930 - loss: 0.6718\n",
      "Epoch 3/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - accuracy: 0.7660 - loss: 0.4823\n",
      "Epoch 4/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 44ms/step - accuracy: 0.9186 - loss: 0.1982\n",
      "Epoch 5/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.9716 - loss: 0.0722\n",
      "Epoch 6/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.9870 - loss: 0.0337\n",
      "Epoch 7/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - accuracy: 0.9930 - loss: 0.0202\n",
      "Epoch 8/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 52ms/step - accuracy: 0.9930 - loss: 0.0188\n",
      "Epoch 9/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 49ms/step - accuracy: 0.9941 - loss: 0.0162\n",
      "Epoch 10/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 55ms/step - accuracy: 0.9952 - loss: 0.0134\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.5097 - loss: 3.0997\n",
      "Loss: 3.0997, Accuacy : 0.5097\n"
     ]
    }
   ],
   "source": [
    "# RNN 모델 \n",
    "from tensorflow.keras import Sequential, layers\n",
    "\n",
    "model_rnn=Sequential(\n",
    "    [\n",
    "    layers.Input(shape=(80,)),\n",
    "    layers.Embedding(input_dim=10000, output_dim=32), # (80,32) 행렬\n",
    "    # layers.Flatten(), # 1차원으로 평탄화\n",
    "    # layers.Dense(64, activation='relu'),\n",
    "    layers.SimpleRNN(64, return_sequences=True),\n",
    "    layers.SimpleRNN(128),\n",
    "    layers.Dense(2, activation='softmax')\n",
    "    ]\n",
    ")\n",
    "# rnn 모델 compile\n",
    "model_rnn.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model_rnn.fit(X_train_pad, y_train, epochs=10, batch_size=200)\n",
    "# evaluate\n",
    "rnn_loss, rnn_accuracy = model_rnn.evaluate(X_test_pad, y_test)\n",
    "print(f\"Loss: {rnn_loss:.4f}, Accuacy : {rnn_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0667c38",
   "metadata": {},
   "source": [
    "# 단어 1000개만 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "47e4031d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import imdb\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words = 1000)\n",
    "(X_train, y_train), (X_test, y_test)\n",
    "\n",
    "#  train, test 데이터 전처리\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "X_train_pad = pad_sequences(X_train, maxlen=80, padding='post', truncating='post')\n",
    "X_test_pad = pad_sequences(X_test, maxlen=80, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cd82a6a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 45ms/step - accuracy: 0.5087 - loss: 0.6992\n",
      "Epoch 2/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.6602 - loss: 0.6082\n",
      "Epoch 3/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.7759 - loss: 0.4833\n",
      "Epoch 4/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.7949 - loss: 0.4550\n",
      "Epoch 5/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.8254 - loss: 0.3948\n",
      "Epoch 6/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.8440 - loss: 0.3616\n",
      "Epoch 7/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - accuracy: 0.8743 - loss: 0.3058\n",
      "Epoch 8/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - accuracy: 0.8938 - loss: 0.2652\n",
      "Epoch 9/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - accuracy: 0.9112 - loss: 0.2254\n",
      "Epoch 10/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.9320 - loss: 0.1764\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.7269 - loss: 0.9225\n",
      "Loss: 0.9225, Accuacy : 0.7269\n"
     ]
    }
   ],
   "source": [
    "# RNN 모델 \n",
    "from tensorflow.keras import Sequential, layers\n",
    "\n",
    "model_rnn=Sequential(\n",
    "    [\n",
    "    layers.Input(shape=(80,)),\n",
    "    layers.Embedding(input_dim=1000, output_dim=32), # (80,32) 행렬\n",
    "    # layers.Flatten(), # 1차원으로 평탄화\n",
    "    # layers.Dense(64, activation='relu'),\n",
    "    layers.SimpleRNN(64, return_sequences=True),\n",
    "    layers.SimpleRNN(128),\n",
    "    layers.Dense(2, activation='softmax')\n",
    "    ]\n",
    ")\n",
    "# rnn 모델 compile\n",
    "model_rnn.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model_rnn.fit(X_train_pad, y_train, epochs=10, batch_size=200)\n",
    "# evaluate\n",
    "rnn_loss, rnn_accuracy = model_rnn.evaluate(X_test_pad, y_test)\n",
    "print(f\"Loss: {rnn_loss:.4f}, Accuacy : {rnn_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796c8179",
   "metadata": {},
   "source": [
    "# 영화평의 길이를 200개로 바꾸기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f0b490c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import imdb\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words = 10000)\n",
    "(X_train, y_train), (X_test, y_test)\n",
    "\n",
    "#  train, test 데이터 전처리\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "X_train_pad = pad_sequences(X_train, maxlen=200, padding='post', truncating='post')\n",
    "X_test_pad = pad_sequences(X_test, maxlen=200, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d80356a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 103ms/step - accuracy: 0.5003 - loss: 0.7065\n",
      "Epoch 2/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 103ms/step - accuracy: 0.5190 - loss: 0.6951\n",
      "Epoch 3/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 96ms/step - accuracy: 0.5601 - loss: 0.6744\n",
      "Epoch 4/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 102ms/step - accuracy: 0.6660 - loss: 0.5522\n",
      "Epoch 5/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 104ms/step - accuracy: 0.7240 - loss: 0.4605\n",
      "Epoch 6/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 104ms/step - accuracy: 0.6383 - loss: 0.6506\n",
      "Epoch 7/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 87ms/step - accuracy: 0.5034 - loss: 0.7185\n",
      "Epoch 8/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 98ms/step - accuracy: 0.5065 - loss: 0.7115\n",
      "Epoch 9/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 97ms/step - accuracy: 0.5015 - loss: 0.7001\n",
      "Epoch 10/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 98ms/step - accuracy: 0.5096 - loss: 0.6935\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.5038 - loss: 0.6928\n",
      "Loss: 0.6928, Accuacy : 0.5038\n"
     ]
    }
   ],
   "source": [
    "# RNN 모델 \n",
    "from tensorflow.keras import Sequential, layers\n",
    "\n",
    "model_rnn=Sequential(\n",
    "    [\n",
    "    layers.Input(shape=(200,)),\n",
    "    layers.Embedding(input_dim=10000, output_dim=32), # (80,32) 행렬\n",
    "    # layers.Flatten(), # 1차원으로 평탄화\n",
    "    # layers.Dense(64, activation='relu'),\n",
    "    layers.SimpleRNN(64, return_sequences=True),\n",
    "    layers.SimpleRNN(128),\n",
    "    layers.Dense(2, activation='softmax')\n",
    "    ]\n",
    ")\n",
    "# rnn 모델 compile\n",
    "model_rnn.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model_rnn.fit(X_train_pad, y_train, epochs=10, batch_size=200)\n",
    "# evaluate\n",
    "rnn_loss, rnn_accuracy = model_rnn.evaluate(X_test_pad, y_test)\n",
    "print(f\"Loss: {rnn_loss:.4f}, Accuacy : {rnn_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30abcee5",
   "metadata": {},
   "source": [
    "# pad_sequence의 truncating과 padding을 pre로 바꾸기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b66cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import imdb \n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words = 10000)\n",
    "(X_train, y_train), (X_test, y_test)\n",
    "\n",
    "#  train, test 데이터 전처리\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "X_train_pad = pad_sequences(X_train, maxlen=80, padding='pre', truncating='pre')\n",
    "X_test_pad = pad_sequences(X_test, maxlen=80, padding='pre', truncating='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d736b300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 51ms/step - accuracy: 0.6802 - loss: 0.5599\n",
      "Epoch 2/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.8639 - loss: 0.3216\n",
      "Epoch 3/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 49ms/step - accuracy: 0.9050 - loss: 0.2383\n",
      "Epoch 4/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - accuracy: 0.9527 - loss: 0.1273\n",
      "Epoch 5/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 44ms/step - accuracy: 0.9843 - loss: 0.0472\n",
      "Epoch 6/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.9925 - loss: 0.0226\n",
      "Epoch 7/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.9949 - loss: 0.0154\n",
      "Epoch 8/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 52ms/step - accuracy: 0.9927 - loss: 0.0209\n",
      "Epoch 9/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.9942 - loss: 0.0161\n",
      "Epoch 10/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.9954 - loss: 0.0130\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.7986 - loss: 1.2778\n",
      "Loss: 1.2778, Accuacy : 0.7986\n"
     ]
    }
   ],
   "source": [
    "# RNN 모델 \n",
    "from tensorflow.keras import Sequential, layers\n",
    "\n",
    "model_rnn=Sequential(\n",
    "    [\n",
    "    layers.Input(shape=(80,)),\n",
    "    layers.Embedding(input_dim=10000, output_dim=32), # (80,32) 행렬\n",
    "    # layers.Flatten(), # 1차원으로 평탄화\n",
    "    # layers.Dense(64, activation='relu'),\n",
    "    layers.SimpleRNN(64, return_sequences=True),\n",
    "    layers.SimpleRNN(128),\n",
    "    layers.Dense(2, activation='softmax')\n",
    "    ]\n",
    ")\n",
    "# rnn 모델 compile\n",
    "model_rnn.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model_rnn.fit(X_train_pad, y_train, epochs=10, batch_size=200)\n",
    "# evaluate\n",
    "rnn_loss, rnn_accuracy = model_rnn.evaluate(X_test_pad, y_test)\n",
    "print(f\"Loss: {rnn_loss:.4f}, Accuacy : {rnn_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9278bab",
   "metadata": {},
   "source": [
    "# RNN 층 (뉴런 128개)을 하나 더 추가 해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "894db46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import imdb\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words = 10000)\n",
    "(X_train, y_train), (X_test, y_test)\n",
    "\n",
    "#  train, test 데이터 전처리\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "X_train_pad = pad_sequences(X_train, maxlen=80, padding='post', truncating='post')\n",
    "X_test_pad = pad_sequences(X_test, maxlen=80, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ebf2df69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-04 16:29:24.928913: I external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.\n",
      "2025-09-04 16:29:26.004266: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_93', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 71ms/step - accuracy: 0.4984 - loss: 0.7187\n",
      "Epoch 2/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 62ms/step - accuracy: 0.5009 - loss: 0.7122\n",
      "Epoch 3/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 64ms/step - accuracy: 0.4992 - loss: 0.7071\n",
      "Epoch 4/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 64ms/step - accuracy: 0.5070 - loss: 0.7000\n",
      "Epoch 5/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 66ms/step - accuracy: 0.5432 - loss: 0.6876\n",
      "Epoch 6/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 70ms/step - accuracy: 0.7014 - loss: 0.5897\n",
      "Epoch 7/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 66ms/step - accuracy: 0.7021 - loss: 0.5881\n",
      "Epoch 8/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 64ms/step - accuracy: 0.7410 - loss: 0.5323\n",
      "Epoch 9/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 72ms/step - accuracy: 0.7441 - loss: 0.5320\n",
      "Epoch 10/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 63ms/step - accuracy: 0.7418 - loss: 0.5339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-04 16:30:53.420446: I external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.\n",
      "2025-09-04 16:30:55.181854: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_41', 36 bytes spill stores, 36 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.7324 - loss: 0.5368\n",
      "Loss: 0.5368, Accuacy : 0.7324\n"
     ]
    }
   ],
   "source": [
    "# RNN 모델 \n",
    "from tensorflow.keras import Sequential, layers\n",
    "\n",
    "model_rnn=Sequential(\n",
    "    [\n",
    "    layers.Input(shape=(80,)),\n",
    "    layers.Embedding(input_dim=1000, output_dim=32), # (80,32) 행렬\n",
    "    # layers.Flatten(), # 1차원으로 평탄화\n",
    "    # layers.Dense(64, activation='relu'),\n",
    "    layers.SimpleRNN(64, return_sequences=True),\n",
    "    layers.SimpleRNN(128, return_sequences=True),\n",
    "    layers.SimpleRNN(128),\n",
    "    layers.Dense(2, activation='softmax')\n",
    "    ]\n",
    ")\n",
    "# rnn 모델 compile\n",
    "model_rnn.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model_rnn.fit(X_train_pad, y_train, epochs=10, batch_size=200)\n",
    "# evaluate\n",
    "rnn_loss, rnn_accuracy = model_rnn.evaluate(X_test_pad, y_test)\n",
    "print(f\"Loss: {rnn_loss:.4f}, Accuacy : {rnn_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c34ebec",
   "metadata": {},
   "source": [
    "| 번호 | 실험 조건                                              | Loss   | Accuracy          |\n",
    "| -- | -------------------------------------------------- | ------ | ----------------- |\n",
    "| 0  | 비교군                                                | 3.0997 | 0.5097            |\n",
    "| 1  | Optimizer: SGD                                     | 0.6958 | 0.5080            |\n",
    "| 2  | 전체 단어 개수 = 1000                                    | 0.9225 | 0.7269            |\n",
    "| 3  | 영화평 길이 = 200                                       | 0.6928 | 0.5038            |\n",
    "| 4  | pad\\_sequences `truncating='pre'`, `padding='pre'` | 1.2778 | 0.7986 (**과대적합**) |\n",
    "| 5  | RNN 층 (뉴런 128) 추가                                  | 0.5368 | 0.7324            |\n",
    "| 6  | CNN                                                  | 0.8909 | 0.7848              |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7fca4d6",
   "metadata": {},
   "source": [
    "# cnn 으로 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "01bcd21f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.6593 - loss: 0.6353 - val_accuracy: 0.7528 - val_loss: 0.5257\n",
      "Epoch 2/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8105 - loss: 0.4268 - val_accuracy: 0.7970 - val_loss: 0.4276\n",
      "Epoch 3/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8930 - loss: 0.2693 - val_accuracy: 0.8042 - val_loss: 0.4329\n",
      "Epoch 4/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9521 - loss: 0.1458 - val_accuracy: 0.8022 - val_loss: 0.5083\n",
      "Epoch 5/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9872 - loss: 0.0607 - val_accuracy: 0.8052 - val_loss: 0.5753\n",
      "Epoch 6/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9977 - loss: 0.0218 - val_accuracy: 0.8064 - val_loss: 0.6473\n",
      "Epoch 7/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9998 - loss: 0.0080 - val_accuracy: 0.8044 - val_loss: 0.7137\n",
      "Epoch 8/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9999 - loss: 0.0038 - val_accuracy: 0.8046 - val_loss: 0.7584\n",
      "Epoch 9/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9999 - loss: 0.0023 - val_accuracy: 0.8044 - val_loss: 0.7975\n",
      "Epoch 10/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.8030 - val_loss: 0.8281\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7848 - loss: 0.8909\n",
      "Loss: 0.8909, Accuracy: 0.7848\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import Sequential, layers\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# -------------------------------\n",
    "# 1. 데이터 불러오기\n",
    "# -------------------------------\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=10000)\n",
    "\n",
    "# -------------------------------\n",
    "# 2. 시퀀스 전처리 (패딩)\n",
    "# -------------------------------\n",
    "X_train_pad = pad_sequences(X_train, maxlen=80, padding='post', truncating='post')\n",
    "X_test_pad = pad_sequences(X_test, maxlen=80, padding='post', truncating='post')\n",
    "\n",
    "# -------------------------------\n",
    "# 3. CNN 모델 정의\n",
    "# -------------------------------\n",
    "model_cnn = Sequential([\n",
    "    layers.Input(shape=(80,)),                        # 시퀀스 길이 80\n",
    "    layers.Embedding(input_dim=10000, output_dim=32), # (batch, 80, 32)\n",
    "\n",
    "    layers.Conv1D(64, 3, activation='relu'),          # 합성곱 (n-gram 특징 추출)\n",
    "    layers.GlobalMaxPooling1D(),                      # 가장 중요한 특징만 추출\n",
    "\n",
    "    layers.Dense(64, activation='relu'),              # 은닉층\n",
    "    layers.Dense(2, activation='softmax')             # 최종 출력 (긍정/부정 분류)\n",
    "])\n",
    "\n",
    "# -------------------------------\n",
    "# 4. 컴파일 & 학습\n",
    "# -------------------------------\n",
    "model_cnn.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "history = model_cnn.fit(X_train_pad, y_train,\n",
    "                        epochs=10,\n",
    "                        batch_size=200,\n",
    "                        validation_split=0.2,\n",
    "                        verbose=1)\n",
    "\n",
    "# -------------------------------\n",
    "# 5. 평가\n",
    "# -------------------------------\n",
    "cnn_loss, cnn_accuracy = model_cnn.evaluate(X_test_pad, y_test)\n",
    "print(f\"Loss: {cnn_loss:.4f}, Accuracy: {cnn_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3495d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3becd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4369650",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_cuda_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
